[RUN_DIR] runs_m1\20251225_203556_T1M1_T1M1_20251225_203549_gpu_seq256_bs1_iters10_layers28_train28_sgd
[ENV] {"python": "3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]", "torch": "2.7.0+cu128", "torch_cuda": "12.8", "gpu": "NVIDIA GeForce RTX 3080 Laptop GPU", "bf16_supported": true, "dtype": "torch.bfloat16", "args": {"mode": "gpu", "model": "./qwen", "seq": 256, "batch": 1, "iters": 10, "layers": 28, "train_layers": 28, "lr": 0.0001, "logdir": "runs_m1", "group": "T1M1_20251225_203549", "seed": 0, "plot": 0, "ckpt_layers": 0, "ckpt_use_reentrant": 0, "prefetch": 1, "pin_mode": "lazy", "cpu_workers": 1, "optim": "sgd", "betas": "0.9,0.999", "eps": 1e-08, "weight_decay": 0.0, "adam_state_dtype": "bf16", "monitor_ms": 5}, "group": "T1M1_20251225_203549"}
[LOAD] tokenizer/model on CPU ...
[ROTARY] found: Qwen3RotaryEmbedding, moved to cuda
[CFG] total_layers=28, use_layers=28, train_layers=28 (range 0..27) mode=gpu
[MOVE] moving embedding/layers/norm to cuda ...

========== [ITER 0] ==========
[ITER 0] wall_s=0.807 forward_s=0.343 backward_s=0.232 optim_s=0.040 peak_alloc=5.86GiB peak_reserved=6.20GiB CPU_RSS=1.28GiB fwd_ms(sum)=337.6 recompute_ms(sum)=0.0 bwd_ms(sum)=204.5

========== [ITER 1] ==========
[ITER 1] wall_s=0.380 forward_s=0.159 backward_s=0.177 optim_s=0.034 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=154.2 recompute_ms(sum)=0.0 bwd_ms(sum)=168.0

========== [ITER 2] ==========
[ITER 2] wall_s=0.374 forward_s=0.150 backward_s=0.177 optim_s=0.034 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=145.2 recompute_ms(sum)=0.0 bwd_ms(sum)=169.2

========== [ITER 3] ==========
[ITER 3] wall_s=0.371 forward_s=0.144 backward_s=0.182 optim_s=0.036 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=140.4 recompute_ms(sum)=0.0 bwd_ms(sum)=173.9

========== [ITER 4] ==========
[ITER 4] wall_s=0.374 forward_s=0.146 backward_s=0.187 optim_s=0.033 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=140.9 recompute_ms(sum)=0.0 bwd_ms(sum)=177.5

========== [ITER 5] ==========
[ITER 5] wall_s=0.371 forward_s=0.143 backward_s=0.184 optim_s=0.034 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=138.1 recompute_ms(sum)=0.0 bwd_ms(sum)=174.5

========== [ITER 6] ==========
[ITER 6] wall_s=0.375 forward_s=0.151 backward_s=0.180 optim_s=0.036 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=144.4 recompute_ms(sum)=0.0 bwd_ms(sum)=171.3

========== [ITER 7] ==========
[ITER 7] wall_s=0.391 forward_s=0.156 backward_s=0.187 optim_s=0.036 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=151.9 recompute_ms(sum)=0.0 bwd_ms(sum)=178.0

========== [ITER 8] ==========
[ITER 8] wall_s=0.369 forward_s=0.152 backward_s=0.173 optim_s=0.034 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=147.8 recompute_ms(sum)=0.0 bwd_ms(sum)=165.9

========== [ITER 9] ==========
[ITER 9] wall_s=0.368 forward_s=0.148 backward_s=0.173 optim_s=0.035 peak_alloc=5.96GiB peak_reserved=6.31GiB CPU_RSS=1.28GiB fwd_ms(sum)=144.1 recompute_ms(sum)=0.0 bwd_ms(sum)=165.0
[SAVED] runs_m1\20251225_203556_T1M1_T1M1_20251225_203549_gpu_seq256_bs1_iters10_layers28_train28_sgd\metrics_iter.csv
[SAVED] runs_m1\20251225_203556_T1M1_T1M1_20251225_203549_gpu_seq256_bs1_iters10_layers28_train28_sgd\metrics_layer.csv
[SAVED] runs_m1\20251225_203556_T1M1_T1M1_20251225_203549_gpu_seq256_bs1_iters10_layers28_train28_sgd\mem_trace.csv
